{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T20:45:00.166304Z","iopub.status.busy":"2024-04-08T20:45:00.165665Z","iopub.status.idle":"2024-04-08T20:45:50.717011Z","shell.execute_reply":"2024-04-08T20:45:50.716088Z","shell.execute_reply.started":"2024-04-08T20:45:00.166267Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision.models import resnet18\n","from torch.utils.data import DataLoader, random_split\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import umap\n","import random\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","from pytorch_metric_learning import losses"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T20:46:08.163627Z","iopub.status.busy":"2024-04-08T20:46:08.162725Z","iopub.status.idle":"2024-04-08T20:46:08.168812Z","shell.execute_reply":"2024-04-08T20:46:08.167581Z","shell.execute_reply.started":"2024-04-08T20:46:08.163591Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["mps\n"]}],"source":["# Set global parameters\n","num_epochs = 10\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n","print(device)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":970},"execution":{"iopub.execute_input":"2024-04-08T20:46:12.572922Z","iopub.status.busy":"2024-04-08T20:46:12.572492Z","iopub.status.idle":"2024-04-08T20:46:18.637085Z","shell.execute_reply":"2024-04-08T20:46:18.636105Z","shell.execute_reply.started":"2024-04-08T20:46:12.572891Z"},"id":"Mvr6tM43UegW","outputId":"57cfce4e-f008-40ad-e5a4-707c9007954a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["# Load and preprocess CIFAR10 dataset\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","\n","# Split the test dataset into 80-20 ratio\n","test_size = len(test_dataset)\n","split_ratio = 0.8\n","test_split_size = int(test_size * split_ratio)\n","val_split_size = test_size - test_split_size\n","test_dataset, val_dataset = random_split(test_dataset, [test_split_size, val_split_size])\n","\n","# Create data loaders\n","train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n","val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"tqUST9pHup1Y"},"source":["## Help functions"]},{"cell_type":"markdown","metadata":{},"source":["### Training function"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Training function\n","def train(model, trainloader, criterion, optimizer, device, epochs):\n","    train_losses = []\n","    for epoch in range(epochs):\n","        model.train()\n","        epoch_loss = 0.0\n","        for images, labels in trainloader:\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            epoch_loss += loss.item()\n","        epoch_loss /= len(trainloader)\n","        train_losses.append(epoch_loss)\n","        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}\")\n","\n","    # Plot training loss\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(range(1, epochs+1), train_losses, marker='o')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Training Loss')\n","    plt.title('Training Loss vs. Epoch')\n","    plt.show()\n","\n","    return train_losses"]},{"cell_type":"markdown","metadata":{},"source":["### Test function"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T14:43:53.132955Z","iopub.status.busy":"2024-04-08T14:43:53.132569Z","iopub.status.idle":"2024-04-08T14:43:53.150673Z","shell.execute_reply":"2024-04-08T14:43:53.149417Z","shell.execute_reply.started":"2024-04-08T14:43:53.132921Z"},"id":"vThvygtxidUx","trusted":true},"outputs":[],"source":["# Test the model with original test data\n","def test_model(model, dataloader, criterion, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    test_loss = 0.0\n","    losses = []\n","\n","    with torch.no_grad():\n","        for images, labels in dataloader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            test_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            losses.append(loss.item())\n","\n","    accuracy = 100 * correct / total\n","    print(f\"Accuracy on original test data: {accuracy:.2f}%\")\n","\n","    # Plotting the test loss\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(losses, label='Test Loss')\n","    plt.title('Test Loss per batch')\n","    plt.xlabel('Batch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","# Test the model with adversarial test data\n","def test_model_adversarial(model, adversarial_images, labels, criterion, device):\n","    model.eval()\n","    adversarial_dataset = torch.utils.data.TensorDataset(torch.tensor(adversarial_images), torch.tensor(labels))\n","    adversarial_dataloader = torch.utils.data.DataLoader(adversarial_dataset, batch_size=128, shuffle=False)\n","\n","    correct = 0\n","    total = 0\n","    adversarial_test_loss = 0.0\n","    adversarial_losses = []\n","\n","    with torch.no_grad():\n","        for images, labels in adversarial_dataloader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            adversarial_test_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            adversarial_losses.append(loss.item())\n","\n","    accuracy = 100 * correct / total\n","    print(f\"Accuracy on adversarial test data: {accuracy:.2f}%\")\n","\n","    # Plotting the adversarial test loss\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(adversarial_losses, label='Adversarial Test Loss')\n","    plt.title('Adversarial Test Loss per batch')\n","    plt.xlabel('Batch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### KNN test function"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T14:47:51.621143Z","iopub.status.busy":"2024-04-08T14:47:51.620741Z","iopub.status.idle":"2024-04-08T14:48:13.047635Z","shell.execute_reply":"2024-04-08T14:48:13.046602Z","shell.execute_reply.started":"2024-04-08T14:47:51.621111Z"},"trusted":true},"outputs":[],"source":["# Extract features from the images using the pre-trained model\n","def extract_features(model, dataloader):\n","    model.eval()\n","    features = []\n","    labels = []\n","    with torch.no_grad():\n","        for images, targets in dataloader:\n","            images = images.cuda()\n","            features_batch = model(images).cpu().numpy()\n","            features.append(features_batch)\n","            labels.append(targets.numpy())\n","    features = np.concatenate(features)\n","    labels = np.concatenate(labels)\n","    return features, labels\n","\n","\n","\n","# Test the model on original test data using KNN\n","def test_model_knn(model, knn_classifier, dataloader):\n","    model.eval()\n","    features, labels = extract_features(model, dataloader)\n","    predicted_labels = knn_classifier.predict(features)\n","    accuracy = accuracy_score(labels, predicted_labels) * 100\n","    print(f\"Accuracy on original test data using KNN: {accuracy:.2f}%\")\n","\n","\n","\n","# Test the model on adversarial test data using KNN\n","def test_model_adversarial_knn(model, knn_classifier, adversarial_images, labels, device):\n","    model.eval()\n","    # Convert adversarial_images to PyTorch tensor and move it to the device\n","    adversarial_images_tensor = torch.tensor(adversarial_images, dtype=torch.float32).to(device)\n","    # Detach the tensor from the computation graph before calling .numpy()\n","    features = model(adversarial_images_tensor).detach().cpu().numpy()\n","    predicted_labels = knn_classifier.predict(features)\n","    accuracy = accuracy_score(labels, predicted_labels) * 100\n","    print(f\"Accuracy on adversarial test data using KNN: {accuracy:.2f}%\")"]},{"cell_type":"markdown","metadata":{},"source":["### Visualize feature map"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T14:43:53.153479Z","iopub.status.busy":"2024-04-08T14:43:53.152699Z","iopub.status.idle":"2024-04-08T14:43:53.164862Z","shell.execute_reply":"2024-04-08T14:43:53.163906Z","shell.execute_reply.started":"2024-04-08T14:43:53.153257Z"},"trusted":true},"outputs":[],"source":["def extract_and_visualize_features(model, images, labels, device):\n","    # Extract features from the second last layer of ResNet18\n","    feature_extractor = nn.Sequential(*list(model.children())[:-1])\n","    feature_extractor = feature_extractor.to(device)\n","    feature_extractor.eval()\n","\n","    # Extract features for each image\n","    adversarial_features = []\n","    for image in images:\n","        image = torch.tensor(image, dtype=torch.float32).to(device)\n","        image = image.unsqueeze(0)  # Add an extra dimension for batch size\n","        features = feature_extractor(image).detach().cpu().numpy()\n","        adversarial_features.append(features)\n","\n","    adversarial_features = np.concatenate(adversarial_features)\n","\n","    # Visualize the features using UMAP\n","    umap_reducer = umap.UMAP(n_components=2)\n","    umap_features = umap_reducer.fit_transform(adversarial_features.reshape(adversarial_features.shape[0], -1))\n","\n","    # Plot UMAP visualization\n","    plt.figure(figsize=(8, 6))\n","    plt.scatter(umap_features[:, 0], umap_features[:, 1], c=labels, cmap='viridis')\n","    plt.colorbar(label='Class')\n","    plt.title('UMAP Visualization of Adversarial Features')\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Train on original dataset/Cross Entropy\n","### 1.1. Generate adverserial samples with FGSM"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T14:39:36.434230Z","iopub.status.busy":"2024-04-08T14:39:36.433936Z","iopub.status.idle":"2024-04-08T14:43:51.704102Z","shell.execute_reply":"2024-04-08T14:43:51.703124Z","shell.execute_reply.started":"2024-04-08T14:39:36.434205Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/homemac/miniconda3/envs/test/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/Users/homemac/miniconda3/envs/test/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/10], Loss: 0.8968\n"]}],"source":["# Setup\n","model = resnet18(pretrained=True)\n","num_features = model.fc.in_features\n","model.fc = nn.Linear(num_features, 10)\n","model = model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Train\n","train_losses = train(model, train_loader, criterion, optimizer, device, num_epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T14:43:51.706430Z","iopub.status.busy":"2024-04-08T14:43:51.705653Z","iopub.status.idle":"2024-04-08T14:43:53.130967Z","shell.execute_reply":"2024-04-08T14:43:53.129816Z","shell.execute_reply.started":"2024-04-08T14:43:51.706390Z"},"trusted":true},"outputs":[],"source":["def combine_fgsm_and_noise(model, images, labels, eps, noise_factor):\n","    # Enable gradients for images\n","    images.requires_grad = True\n","\n","    # Perform FGSM attack only if gradients are enabled\n","    if images.requires_grad:\n","        outputs = model(images)\n","        model.zero_grad()\n","        cost = criterion(outputs, labels)\n","        cost.backward()\n","        attack_images = images + eps * images.grad.sign()\n","        attack_images = torch.clamp(attack_images, 0, 1)\n","    else:\n","        attack_images = images\n","\n","    # Detach the images to prevent further gradient computation\n","    attack_images = attack_images.detach()\n","\n","    # Convert images to numpy to add noise\n","    attack_images_np = attack_images.cpu().numpy()\n","\n","    # Add Gaussian noise\n","    attack_images_np += noise_factor * np.random.normal(loc=0, scale=1, size=attack_images_np.shape)\n","    attack_images_np = np.clip(attack_images_np, 0, 1)\n","\n","    # Convert back to torch tensor\n","    attack_images_with_noise = torch.tensor(attack_images_np, requires_grad=False).to(device)\n","\n","    return attack_images_with_noise\n","\n","\n","# Parameters for FGSM and noise\n","eps = 0.1\n","noise_factor = 0.05\n","\n","model.eval()\n","adversarial_images = []\n","original_images = []\n","labels = []\n","\n","for images, targets in val_loader:\n","    images, targets = images.to(device), targets.to(device)\n","    # Use the new combined function\n","    images_with_attack = combine_fgsm_and_noise(model, images, targets, eps, noise_factor).detach().cpu().numpy()\n","    adversarial_images.append(images_with_attack)\n","    original_images.append(images.detach().cpu().numpy())\n","    labels.append(targets.detach().cpu().numpy())\n","\n","# Convert lists to numpy arrays\n","adversarial_images = np.concatenate(adversarial_images)\n","original_images = np.concatenate(original_images)\n","labels = np.concatenate(labels)\n","\n","\n","# Display some adversarial images\n","num_images = 5\n","indices = np.random.choice(len(adversarial_images), num_images, replace=False)\n","plt.figure(figsize=(10, 4))\n","for i, index in enumerate(indices):\n","    plt.subplot(1, num_images, i+1)\n","    plt.imshow(np.transpose(adversarial_images[index], (1, 2, 0)))\n","    plt.axis('off')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Vp0dMYbIu29a"},"source":["### 1.2. Test original data/Cross entropy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_features, train_labels = extract_features(model, train_loader)\n","\n","# Train KNN classifier\n","knn_classifier = KNeighborsClassifier(n_neighbors=5)\n","knn_classifier.fit(train_features, train_labels)\n","\n","test_model_knn(model, knn_classifier, test_loader)\n","test_model_adversarial_knn(model, knn_classifier, adversarial_images, labels, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Test the model on original test data\n","test_model(model, test_loader, criterion, device)\n","\n","# Test the model on adversarial test data\n","test_model_adversarial(model, adversarial_images, labels, criterion, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T10:26:53.362960Z","iopub.status.busy":"2024-04-08T10:26:53.362602Z","iopub.status.idle":"2024-04-08T10:27:14.304366Z","shell.execute_reply":"2024-04-08T10:27:14.303382Z","shell.execute_reply.started":"2024-04-08T10:26:53.362929Z"},"id":"MgAK02DDvOaR","trusted":true},"outputs":[],"source":["# Call the function to extract and visualize features\n","extract_and_visualize_features(model, adversarial_images, labels, device)"]},{"cell_type":"markdown","metadata":{"id":"GLd3WqG2vR5G"},"source":["# 2. Train on agumented data/Cross entropy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":207},"execution":{"iopub.execute_input":"2024-04-08T14:48:31.186234Z","iopub.status.busy":"2024-04-08T14:48:31.185277Z","iopub.status.idle":"2024-04-08T14:54:02.334418Z","shell.execute_reply":"2024-04-08T14:54:02.333412Z","shell.execute_reply.started":"2024-04-08T14:48:31.186191Z"},"id":"ELLuguNb6M9d","outputId":"16e69259-ede5-498c-acdd-bbd560dad827","trusted":true},"outputs":[],"source":["# Function to apply FGSM attack with 50% probability to each batch\n","def apply_fgsm(model, images, labels, criterion, eps):\n","    # Enable gradients for images\n","    images.requires_grad = True\n","\n","    # Perform FGSM attack only if gradients are enabled\n","    if images.requires_grad:\n","        outputs = model(images)\n","        model.zero_grad()\n","        cost = criterion(outputs, labels)\n","        cost.backward()\n","        attack_images = images + eps * images.grad.sign()\n","        attack_images = torch.clamp(attack_images, 0, 1)\n","    else:\n","        attack_images = images\n","\n","    return attack_images\n","\n","# Modified training function to apply FGSM with 50% probability\n","def train_with_fgsm(model, trainloader, criterion, optimizer, device, epochs, eps=0.1):\n","    train_losses = []\n","    for epoch in range(epochs):\n","        model.train()\n","        epoch_loss = 0.0\n","        for images, labels in trainloader:\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            \n","            # Apply FGSM attack with 50% probability\n","            if torch.rand(1) < 0.5:\n","                images = apply_fgsm(model, images, labels, criterion, eps)\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            epoch_loss += loss.item()\n","        epoch_loss /= len(trainloader)\n","        train_losses.append(epoch_loss)\n","        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}\")\n","\n","    # Plot training loss\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(range(1, epochs+1), train_losses, marker='o')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Training Loss')\n","    plt.title('Training Loss vs. Epoch')\n","    plt.show()\n","\n","    return train_losses"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Setup and Retrain\n","new_model = resnet18(pretrained=True)\n","num_features = new_model.fc.in_features\n","new_model.fc = nn.Linear(num_features, 10)\n","new_model = new_model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(new_model.parameters(), lr=0.001)\n","\n","# Train\n","train_losses = train_with_fgsm(new_model, train_loader, criterion, optimizer, device, num_epochs)"]},{"cell_type":"markdown","metadata":{},"source":["### 2.1. Test agumented data/Cross entropy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T14:54:02.336490Z","iopub.status.busy":"2024-04-08T14:54:02.336171Z","iopub.status.idle":"2024-04-08T14:54:05.479042Z","shell.execute_reply":"2024-04-08T14:54:05.478130Z","shell.execute_reply.started":"2024-04-08T14:54:02.336464Z"},"trusted":true},"outputs":[],"source":["# Test the new model on original test data\n","test_model(new_model, test_loader, criterion, device)\n","\n","# Test the new model on adversarial test data\n","test_model_adversarial(new_model, adversarial_images, labels, criterion, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T14:57:22.847406Z","iopub.status.busy":"2024-04-08T14:57:22.846759Z","iopub.status.idle":"2024-04-08T14:57:43.954112Z","shell.execute_reply":"2024-04-08T14:57:43.953084Z","shell.execute_reply.started":"2024-04-08T14:57:22.847370Z"},"trusted":true},"outputs":[],"source":["# KNN test\n","train_features, train_labels = extract_features(new_model, train_loader)\n","\n","# Train KNN classifier\n","knn_classifier = KNeighborsClassifier(n_neighbors=5)\n","knn_classifier.fit(train_features, train_labels)\n","\n","test_model_knn(new_model, knn_classifier, test_loader)\n","test_model_adversarial_knn(new_model, knn_classifier, adversarial_images, labels, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T14:58:55.490121Z","iopub.status.busy":"2024-04-08T14:58:55.489153Z","iopub.status.idle":"2024-04-08T14:59:17.028175Z","shell.execute_reply":"2024-04-08T14:59:17.027172Z","shell.execute_reply.started":"2024-04-08T14:58:55.490084Z"},"id":"l7IOonsl6TWC","trusted":true},"outputs":[],"source":["# Call the function to extract and visualize features\n","extract_and_visualize_features(new_model, adversarial_images, labels, device)"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Train on original data/Circle loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Training function\n","def train_with_circle_loss(model, trainloader, optimizer, device, epochs):\n","    train_losses = []\n","    for epoch in range(epochs):\n","        model.train()\n","        epoch_loss = 0.0\n","        for images, labels in trainloader:\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            # Calculate embeddings\n","            embeddings = outputs\n","            # Calculate Circle Loss\n","            loss = circle_loss(embeddings, labels)\n","            loss.backward()\n","            optimizer.step()\n","            epoch_loss += loss.item()\n","        epoch_loss /= len(trainloader)\n","        train_losses.append(epoch_loss)\n","        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}\")\n","\n","    # Plot training loss\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(range(1, epochs+1), train_losses, marker='o')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Training Loss')\n","    plt.title('Training Loss vs. Epoch')\n","    plt.show()\n","\n","    return train_losses"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Setup and Retrain\n","new_model2 = resnet18(pretrained=True)\n","num_features = new_model2.fc.in_features\n","new_model2.fc = nn.Linear(num_features, 10)\n","new_model2 = new_model2.to(device)\n","\n","circle_loss = losses.CircleLoss()\n","optimizer = optim.Adam(new_model2.parameters(), lr=0.001)\n","\n","# Train\n","train_losses_circle = train_with_circle_loss(new_model2, train_loader, optimizer, device, num_epochs)"]},{"cell_type":"markdown","metadata":{},"source":["### 3.1. Test agumented data/Cross entropy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# KNN test\n","train_features, train_labels = extract_features(new_model2, train_loader)\n","\n","# Train KNN classifier\n","knn_classifier = KNeighborsClassifier(n_neighbors=5)\n","knn_classifier.fit(train_features, train_labels)\n","\n","\n","test_model_knn(new_model2, knn_classifier, test_loader)\n","test_model_adversarial_knn(new_model2, knn_classifier, adversarial_images, labels, device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Test the new model on original test data\n","test_model(new_model2, test_loader, criterion, device)\n","\n","# Test the new model on adversarial test data\n","test_model_adversarial(new_model2, adversarial_images, labels, criterion, device)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNN+aV+hn1To0ZSoD3DW3bo","gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"test","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
