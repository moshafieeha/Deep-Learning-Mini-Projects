{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary libraries and packages\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nfrom typing import Type\nimport numpy as np\nfrom torch.utils.data import Subset","metadata":{"id":"-0BFGi6M-EfZ","execution":{"iopub.status.busy":"2024-04-07T09:19:04.838315Z","iopub.execute_input":"2024-04-07T09:19:04.838644Z","iopub.status.idle":"2024-04-07T09:19:16.360057Z","shell.execute_reply.started":"2024-04-07T09:19:04.838617Z","shell.execute_reply":"2024-04-07T09:19:16.359272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Global parameters\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nnum_epochs = 10\nbatch_size = 64","metadata":{"id":"orFwcWdR-Efa","execution":{"iopub.status.busy":"2024-04-07T09:19:16.361739Z","iopub.execute_input":"2024-04-07T09:19:16.362121Z","iopub.status.idle":"2024-04-07T09:19:16.416596Z","shell.execute_reply.started":"2024-04-07T09:19:16.362096Z","shell.execute_reply":"2024-04-07T09:19:16.415673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Train the base model","metadata":{"id":"zT4cZIfY-Efb"}},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion * planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512 * block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.maxpool(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n\n        out = F.adaptive_avg_pool2d(out, (1, 1))\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\ndef ResNet18():\n    return ResNet(BasicBlock, [2, 2, 2, 2])","metadata":{"id":"mtGAXiULdsut","execution":{"iopub.status.busy":"2024-04-07T09:19:16.418011Z","iopub.execute_input":"2024-04-07T09:19:16.418400Z","iopub.status.idle":"2024-04-07T09:19:16.438611Z","shell.execute_reply.started":"2024-04-07T09:19:16.418361Z","shell.execute_reply":"2024-04-07T09:19:16.437854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load and normalize the SVHN dataset\ntransform_svhn = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ntrainset_svhn = torchvision.datasets.SVHN(root='./data', split='train', download=True, transform=transform_svhn)\ntrainloader_svhn = DataLoader(trainset_svhn, batch_size=batch_size, shuffle=True, num_workers=2)\n\ntestset_svhn = torchvision.datasets.SVHN(root='./data', split='test', download=True, transform=transform_svhn)\ntestloader_svhn = DataLoader(testset_svhn, batch_size=batch_size, shuffle=False, num_workers=2)\n\n\n\n# Load and normalize the MNIST dataset\ntransform_mnist = transforms.Compose([\n    transforms.Resize((32, 32)),  # Resize to be compatible with SVHN\n    transforms.Grayscale(num_output_channels=3),  # Convert 1 channel grayscale to 3 channel grayscale\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ntestset_mnist = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform_mnist)\ntestloader_mnist = DataLoader(testset_mnist, batch_size=batch_size, shuffle=False, num_workers=2)","metadata":{"id":"FG6KCsCNgQgL","outputId":"2c59a3a8-7253-40de-f1d0-cb84e7462037","execution":{"iopub.status.busy":"2024-04-07T09:19:16.439736Z","iopub.execute_input":"2024-04-07T09:19:16.440159Z","iopub.status.idle":"2024-04-07T09:19:45.082113Z","shell.execute_reply.started":"2024-04-07T09:19:16.440128Z","shell.execute_reply":"2024-04-07T09:19:45.081334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, trainloader, criterion, optimizer, device, epochs):\n    model.train()\n    loss_values = []  # List to store loss values\n\n    for epoch in range(epochs):\n        running_loss = 0.0\n        for i, data in enumerate(trainloader, 0):\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n        # Print the average loss of the entire epoch\n        avg_loss = running_loss / len(trainloader)\n        print(f'[{epoch + 1}] loss: {avg_loss:.3f}')\n        loss_values.append(avg_loss)\n\n    # Plot the training loss\n    plt.figure(figsize=(10, 5))\n    plt.plot(loss_values, label='Training Loss')\n    plt.title('Training Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n\n\n\ndef evaluate(model, testloader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    accuracy = 100 * correct / total\n    return accuracy","metadata":{"id":"Rb5CwzwigUDR","execution":{"iopub.status.busy":"2024-04-07T09:20:35.479459Z","iopub.execute_input":"2024-04-07T09:20:35.480144Z","iopub.status.idle":"2024-04-07T09:20:35.490856Z","shell.execute_reply.started":"2024-04-07T09:20:35.480115Z","shell.execute_reply":"2024-04-07T09:20:35.489972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup and repeat Train\nnet = ResNet18()\nnet = net.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n\ntrain(net, trainloader_svhn, criterion, optimizer, device, num_epochs)","metadata":{"id":"aPH9XfzRgW2z","outputId":"78a3e36c-e8e0-47f3-9a6c-16f5d5a7cc81","execution":{"iopub.status.busy":"2024-04-06T20:51:07.235384Z","iopub.execute_input":"2024-04-06T20:51:07.235708Z","iopub.status.idle":"2024-04-06T20:54:38.116210Z","shell.execute_reply.started":"2024-04-06T20:51:07.235679Z","shell.execute_reply":"2024-04-06T20:54:38.115185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\nsvhn_accuracy = evaluate(net, testloader_svhn, device)\nprint(f'Accuracy of the network on the SVHN test images: {svhn_accuracy:.2f}%')\n\nmnist_accuracy = evaluate(net, testloader_mnist, device)\nprint(f'Accuracy of the network on the MNIST test images: {mnist_accuracy:.2f}%')","metadata":{"id":"mqFyR9SRgW0d","outputId":"f986b3f9-6c88-45b1-df36-cbd1bff3cb34","execution":{"iopub.status.busy":"2024-04-06T20:54:38.117613Z","iopub.execute_input":"2024-04-06T20:54:38.117918Z","iopub.status.idle":"2024-04-06T20:54:46.123803Z","shell.execute_reply.started":"2024-04-06T20:54:38.117892Z","shell.execute_reply":"2024-04-06T20:54:46.122653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Enhance the generalization","metadata":{"id":"IwsGHUjD-Efe"}},{"cell_type":"markdown","source":"## 2.1 Model architecture modification","metadata":{"id":"JeieJTCU-Efe"}},{"cell_type":"code","source":"class BasicBlockNoBN(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlockNoBN, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)  # bias is True now\n        # self.bn1 = nn.BatchNorm2d(planes)  # Removed batch normalization\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=True)  # bias is True now\n        # self.bn2 = nn.BatchNorm2d(planes)  # Removed batch normalization\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=True)  # bias is True now\n                # Batch normalization is removed from shortcut as well\n            )\n\n    def forward(self, x):\n        out = F.relu(self.conv1(x))\n        out = self.conv2(out)\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\nclass ResNetNoBN(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNetNoBN, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=True)  # bias is True now\n        # self.bn1 = nn.BatchNorm2d(64)  # Removed batch normalization\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512 * block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.conv1(x))  # Removed the batch normalization\n        out = self.maxpool(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n\n        out = F.adaptive_avg_pool2d(out, (1, 1))\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\ndef ResNet18NoBN():\n    return ResNetNoBN(BasicBlockNoBN, [2, 2, 2, 2])","metadata":{"execution":{"iopub.status.busy":"2024-04-06T20:54:46.126078Z","iopub.execute_input":"2024-04-06T20:54:46.126568Z","iopub.status.idle":"2024-04-06T20:54:46.147291Z","shell.execute_reply.started":"2024-04-06T20:54:46.126530Z","shell.execute_reply":"2024-04-06T20:54:46.146328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup and repeat Train\nnet = ResNet18NoBN()\nnet = net.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n\ntrain(net, trainloader_svhn, criterion, optimizer, device, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T20:54:46.148544Z","iopub.execute_input":"2024-04-06T20:54:46.149332Z","iopub.status.idle":"2024-04-06T20:57:54.214125Z","shell.execute_reply.started":"2024-04-06T20:54:46.149297Z","shell.execute_reply":"2024-04-06T20:57:54.213035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\nsvhn_accuracy = evaluate(net, testloader_svhn, device)\nprint(f'Accuracy of the network on the SVHN test images: {svhn_accuracy:.2f}%')\n\nmnist_accuracy = evaluate(net, testloader_mnist, device)\nprint(f'Accuracy of the network on the MNIST test images: {mnist_accuracy:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-04-06T20:57:54.218220Z","iopub.execute_input":"2024-04-06T20:57:54.218516Z","iopub.status.idle":"2024-04-06T20:58:01.896730Z","shell.execute_reply.started":"2024-04-06T20:57:54.218489Z","shell.execute_reply":"2024-04-06T20:58:01.895632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2. Loss function\n\nYou can find different implementation of Label Smoothing in PyTorch in this link: https://stackoverflow.com/questions/55681502/label-smoothing-in-pytorch\n\nIn this code I test the accuracy of my implementation with built-in function of Pytorch.","metadata":{"id":"HKG6Dx8x-Eff"}},{"cell_type":"code","source":"class LabelSmoothingCrossEntropyLoss(nn.Module):\n    def __init__(self, smoothing=0.1):\n        super(LabelSmoothingCrossEntropyLoss, self).__init__()\n        self.smoothing = smoothing\n\n    def forward(self, input, target):\n        log_probs = F.log_softmax(input, dim=-1)\n\n        # Compute the smoothed labels\n        num_classes = input.size(-1)\n        with torch.no_grad():\n            true_dist = torch.zeros_like(log_probs)\n            true_dist.fill_(self.smoothing / (num_classes - 1))\n            true_dist.scatter_(1, target.data.unsqueeze(1), 1.0 - self.smoothing)\n\n        # Return the average loss\n        return torch.mean(torch.sum(-true_dist * log_probs, dim=-1))","metadata":{"id":"Cjr_8kQQ-Eff","execution":{"iopub.status.busy":"2024-04-07T09:19:45.083821Z","iopub.execute_input":"2024-04-07T09:19:45.084240Z","iopub.status.idle":"2024-04-07T09:19:45.091089Z","shell.execute_reply.started":"2024-04-07T09:19:45.084191Z","shell.execute_reply":"2024-04-07T09:19:45.090252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup and repeat Train\nnet = ResNet18()\nnet = net.to(device)\n\n# criterion = LabelSmoothingCrossEntropyLoss(smoothing=0.25)\n\ncriterion = torch.nn.CrossEntropyLoss(weight=None, size_average=None, \n                          ignore_index=- 100, reduce=None, \n                          reduction='mean', label_smoothing=0.25)\n\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n\ntrain(net, trainloader_svhn, criterion, optimizer, device, num_epochs)","metadata":{"id":"I9yw64CD-Eff","execution":{"iopub.status.busy":"2024-04-06T20:58:01.908164Z","iopub.execute_input":"2024-04-06T20:58:01.908436Z","iopub.status.idle":"2024-04-06T21:01:36.783171Z","shell.execute_reply.started":"2024-04-06T20:58:01.908413Z","shell.execute_reply":"2024-04-06T21:01:36.782007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\nsvhn_accuracy = evaluate(net, testloader_svhn, device)\nprint(f'Accuracy of the network on the SVHN test images: {svhn_accuracy:.2f}%')\n\nmnist_accuracy = evaluate(net, testloader_mnist, device)\nprint(f'Accuracy of the network on the MNIST test images: {mnist_accuracy:.2f}%')","metadata":{"id":"uqT9Zfv4keRm","outputId":"7a22e815-c9dc-4ed0-b303-a16c00286a31","execution":{"iopub.status.busy":"2024-04-06T21:01:36.784666Z","iopub.execute_input":"2024-04-06T21:01:36.785031Z","iopub.status.idle":"2024-04-06T21:01:44.930282Z","shell.execute_reply.started":"2024-04-06T21:01:36.784979Z","shell.execute_reply":"2024-04-06T21:01:44.929062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.3 Data agumentaiton","metadata":{"id":"HBPIZKiE-Efg"}},{"cell_type":"code","source":"# Define the augmentation pipeline\naugmentation_transforms = transforms.Compose([\n#     transforms.RandomRotation(degrees=10),  # Rotate +/- 10 degrees\n#     transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 10% translation\n    transforms.RandomResizedCrop(size=(32, 32), scale=(0.8, 1.2)),  # Scaling between 80% and 120%\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Randomly change brightness, contrast, and saturation\n    transforms.RandomPerspective(distortion_scale=0.5),  # perspective transformations\n    \n    # Top gener: Color + Rotate + Size\n    # Top acc: Perspective + Color + Size\n    # Intersection: Color + Size\n    # All\n    \n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\n# Apply the augmentation pipeline only to the training data\ntrainloader_svhn = torch.utils.data.DataLoader(\n    datasets.SVHN(root='./data', split='train', download=True, transform=augmentation_transforms),\n    batch_size=batch_size, shuffle=True)","metadata":{"id":"z6y21RljpKiq","outputId":"e234f45d-e8a9-4160-d038-c2c2d2299970","execution":{"iopub.status.busy":"2024-04-06T21:01:44.931953Z","iopub.execute_input":"2024-04-06T21:01:44.932376Z","iopub.status.idle":"2024-04-06T21:01:47.306198Z","shell.execute_reply.started":"2024-04-06T21:01:44.932339Z","shell.execute_reply":"2024-04-06T21:01:47.305336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup and repeat Train\nnet = ResNet18()\nnet = net.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n\ntrain(net, trainloader_svhn, criterion, optimizer, device, num_epochs)","metadata":{"id":"4BQ31B3NpKLd","outputId":"833dbe0d-d26b-4e04-c428-9616768d2065","execution":{"iopub.status.busy":"2024-04-06T21:01:47.307474Z","iopub.execute_input":"2024-04-06T21:01:47.307806Z","iopub.status.idle":"2024-04-06T21:20:49.961712Z","shell.execute_reply.started":"2024-04-06T21:01:47.307778Z","shell.execute_reply":"2024-04-06T21:20:49.960982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\nsvhn_accuracy = evaluate(net, testloader_svhn, device)\nprint(f'Accuracy of the network on the SVHN test images: {svhn_accuracy:.2f}%')\n\nmnist_accuracy = evaluate(net, testloader_mnist, device)\nprint(f'Accuracy of the network on the MNIST test images: {mnist_accuracy:.2f}%')","metadata":{"id":"U3nA1ea2puJS","outputId":"56d014ce-1a12-4f27-e3c9-b04fe6c15c29","execution":{"iopub.status.busy":"2024-04-06T21:20:49.962986Z","iopub.execute_input":"2024-04-06T21:20:49.963348Z","iopub.status.idle":"2024-04-06T21:20:57.890897Z","shell.execute_reply.started":"2024-04-06T21:20:49.963314Z","shell.execute_reply":"2024-04-06T21:20:57.889775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.4 Transfer learning","metadata":{}},{"cell_type":"markdown","source":"Need to run earlier dataloaders to remove the effect of recent data agumentation","metadata":{}},{"cell_type":"code","source":"# Setup and repeat Train\nnet = models.resnet18(pretrained=True)\n# Change class numbers to 10\nnet.fc = nn.Linear(net.fc.in_features, 10)\nnet = net.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n\ntrain(net, trainloader_svhn, criterion, optimizer, device, num_epochs)\n","metadata":{"id":"5plBgThrpJx5","execution":{"iopub.status.busy":"2024-04-07T10:45:01.977299Z","iopub.execute_input":"2024-04-07T10:45:01.978009Z","iopub.status.idle":"2024-04-07T10:48:34.358408Z","shell.execute_reply.started":"2024-04-07T10:45:01.977976Z","shell.execute_reply":"2024-04-07T10:48:34.357281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\nsvhn_accuracy = evaluate(net, testloader_svhn, device)\nprint(f'Accuracy of the network on the SVHN test images: {svhn_accuracy:.2f}%')\n\nmnist_accuracy = evaluate(net, testloader_mnist, device)\nprint(f'Accuracy of the network on the MNIST test images: {mnist_accuracy:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T10:48:34.360553Z","iopub.execute_input":"2024-04-07T10:48:34.360928Z","iopub.status.idle":"2024-04-07T10:48:42.021149Z","shell.execute_reply.started":"2024-04-07T10:48:34.360890Z","shell.execute_reply":"2024-04-07T10:48:42.019979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.5 Optimizer","metadata":{}},{"cell_type":"code","source":"# Setup and repeat Train\nnet = ResNet18()\nnet = net.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=5e-4)\n\ntrain(net, trainloader_svhn, criterion, optimizer, device, num_epochs)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T16:46:24.742138Z","iopub.execute_input":"2024-04-06T16:46:24.742826Z","iopub.status.idle":"2024-04-06T16:50:10.266570Z","shell.execute_reply.started":"2024-04-06T16:46:24.742797Z","shell.execute_reply":"2024-04-06T16:50:10.265598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\nsvhn_accuracy = evaluate(net, testloader_svhn, device)\nprint(f'Accuracy of the network on the SVHN test images: {svhn_accuracy:.2f}%')\n\nmnist_accuracy = evaluate(net, testloader_mnist, device)\nprint(f'Accuracy of the network on the MNIST test images: {mnist_accuracy:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-04-06T16:50:17.383989Z","iopub.execute_input":"2024-04-06T16:50:17.384381Z","iopub.status.idle":"2024-04-06T16:50:25.443532Z","shell.execute_reply.started":"2024-04-06T16:50:17.384349Z","shell.execute_reply":"2024-04-06T16:50:25.442482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Rverese training","metadata":{}},{"cell_type":"markdown","source":"## 3.1. Unsupervised\nChoose the best setting from the previous step and retrain the model on MNIST instead of SVHN.","metadata":{}},{"cell_type":"markdown","source":"We need new data agumentation because the MNIST dataset contains grayscale images with a single channel, but the normalization was set up for three-channel (RGB) image.","metadata":{}},{"cell_type":"code","source":"mnist_augmentation_transforms = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.Grayscale(num_output_channels=3),\n    \n    transforms.RandomResizedCrop(size=(32, 32), scale=(0.8, 1.2)),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.RandomPerspective(distortion_scale=0.5),\n\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])","metadata":{"execution":{"iopub.status.busy":"2024-04-07T09:40:28.243131Z","iopub.execute_input":"2024-04-07T09:40:28.244299Z","iopub.status.idle":"2024-04-07T09:40:28.250975Z","shell.execute_reply.started":"2024-04-07T09:40:28.244262Z","shell.execute_reply":"2024-04-07T09:40:28.249980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reload the MNIST dataset\ntrainset_mnist = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform_mnist)\n\n# Apply the augmentation pipeline only to the training data\ntrainloader_mnist = torch.utils.data.DataLoader(\n    datasets.MNIST(root='./data', train=True, download=True, transform=mnist_augmentation_transforms), batch_size=64, shuffle=True) # Agumentation from section 2.3\n\ntestset_mnist = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform_mnist)\ntestloader_mnist = DataLoader(testset_mnist, batch_size=batch_size, shuffle=False, num_workers=2)\n\n\n# Reload the SVHN dataset\ntestset_svhn = torchvision.datasets.SVHN(root='./data', split='test', download=True, transform=transform_svhn)\ntestloader_svhn = DataLoader(testset_svhn, batch_size=batch_size, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T09:40:28.253037Z","iopub.execute_input":"2024-04-07T09:40:28.253510Z","iopub.status.idle":"2024-04-07T09:40:29.226619Z","shell.execute_reply.started":"2024-04-07T09:40:28.253477Z","shell.execute_reply":"2024-04-07T09:40:29.225767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup and repeat Train\nnet = models.resnet18(pretrained=True) #Pre-trained from section 2.4\nnet.fc = nn.Linear(net.fc.in_features, 10)\nnet = net.to(device)\ncriterion = LabelSmoothingCrossEntropyLoss(smoothing=0.25) # With label smoothing from section 2.2\noptimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=5e-4) # Adam from 2.5 section\n\ntrain(net, trainloader_mnist, criterion, optimizer, device, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T11:05:26.181955Z","iopub.execute_input":"2024-04-07T11:05:26.182339Z","iopub.status.idle":"2024-04-07T11:22:14.594284Z","shell.execute_reply.started":"2024-04-07T11:05:26.182304Z","shell.execute_reply":"2024-04-07T11:22:14.593373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\nsvhn_accuracy = evaluate(net, testloader_svhn, device)\nprint(f'Accuracy of the network on the SVHN test images: {svhn_accuracy:.2f}%')\n\nmnist_accuracy = evaluate(net, testloader_mnist, device)\nprint(f'Accuracy of the network on the MNIST test images: {mnist_accuracy:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T11:22:14.596475Z","iopub.execute_input":"2024-04-07T11:22:14.597137Z","iopub.status.idle":"2024-04-07T11:22:22.326543Z","shell.execute_reply.started":"2024-04-07T11:22:14.597102Z","shell.execute_reply":"2024-04-07T11:22:22.325404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2. Supervised","metadata":{}},{"cell_type":"markdown","source":"### Fine-tune","metadata":{}},{"cell_type":"code","source":"# Freeze convolutional layers\nfor param in net.parameters():\n    param.requires_grad = False\n\n# Unfreeze the classifier layers\nfor param in net.fc.parameters():\n    param.requires_grad = True\n\n# Optimizer for the classifier\noptimizer = optim.Adam(net.fc.parameters(), lr=0.001, weight_decay=5e-4)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T11:22:22.327885Z","iopub.execute_input":"2024-04-07T11:22:22.328202Z","iopub.status.idle":"2024-04-07T11:22:22.336009Z","shell.execute_reply.started":"2024-04-07T11:22:22.328173Z","shell.execute_reply":"2024-04-07T11:22:22.335197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After training on MNIST, fine-tune the classifier using a subset of SVHN test set\nnum_samples = 500\nindices = np.random.choice(len(testset_svhn), num_samples, replace=False)\nsubset_svhn = Subset(testset_svhn, indices)\n\n# Create a DataLoader for the SVHN subset\nsubset_loader_svhn = DataLoader(subset_svhn, batch_size=batch_size, shuffle=True, num_workers=2)\n\n# Continue training (fine-tuning) on the SVHN subset\ntrain(net, subset_loader_svhn, criterion, optimizer, device, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T11:22:22.337019Z","iopub.execute_input":"2024-04-07T11:22:22.337292Z","iopub.status.idle":"2024-04-07T11:22:24.642416Z","shell.execute_reply.started":"2024-04-07T11:22:22.337270Z","shell.execute_reply":"2024-04-07T11:22:24.641410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\nsvhn_accuracy = evaluate(net, testloader_svhn, device)\nprint(f'Accuracy of the network on the SVHN test images: {svhn_accuracy:.2f}%')\n\nmnist_accuracy = evaluate(net, testloader_mnist, device)\nprint(f'Accuracy of the network on the MNIST test images: {mnist_accuracy:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T11:22:24.644995Z","iopub.execute_input":"2024-04-07T11:22:24.645500Z","iopub.status.idle":"2024-04-07T11:22:32.425399Z","shell.execute_reply.started":"2024-04-07T11:22:24.645459Z","shell.execute_reply":"2024-04-07T11:22:32.424295Z"},"trusted":true},"execution_count":null,"outputs":[]}]}