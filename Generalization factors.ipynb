{"cells":[{"cell_type":"markdown","metadata":{"id":"qopTGRxZ-EfX"},"source":["# 1. Generalization"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T14:21:41.983492Z","iopub.status.busy":"2024-04-04T14:21:41.983131Z","iopub.status.idle":"2024-04-04T14:21:49.454351Z","shell.execute_reply":"2024-04-04T14:21:49.453576Z","shell.execute_reply.started":"2024-04-04T14:21:41.983456Z"},"id":"-0BFGi6M-EfZ","trusted":true},"outputs":[],"source":["# Import necessary libraries and packages\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","from typing import Type\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T14:26:28.586154Z","iopub.status.busy":"2024-04-04T14:26:28.585377Z","iopub.status.idle":"2024-04-04T14:26:28.590888Z","shell.execute_reply":"2024-04-04T14:26:28.589800Z","shell.execute_reply.started":"2024-04-04T14:26:28.586119Z"},"id":"orFwcWdR-Efa","trusted":true},"outputs":[],"source":["# Global parameters\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","num_epochs = 10"]},{"cell_type":"markdown","metadata":{"id":"zT4cZIfY-Efb"},"source":["## 1.1. Train the base model"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:51:08.661075Z","iopub.status.busy":"2024-04-04T10:51:08.660632Z","iopub.status.idle":"2024-04-04T10:51:09.094938Z","shell.execute_reply":"2024-04-04T10:51:09.093938Z","shell.execute_reply.started":"2024-04-04T10:51:08.661028Z"},"id":"mtGAXiULdsut","trusted":true},"outputs":[],"source":["class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion * planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion * planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","    \n","    \n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=1000):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        # Modified the kernel size, stride, and padding to match the original ResNet-18\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512 * block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks - 1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","\n","        # Changed to adaptive average pooling for flexibility\n","        out = F.adaptive_avg_pool2d(out, (1, 1))\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","def ResNet18():\n","    return ResNet(BasicBlock, [2, 2, 2, 2])"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-04-04T14:22:55.497054Z","iopub.status.busy":"2024-04-04T14:22:55.496222Z","iopub.status.idle":"2024-04-04T14:23:35.723816Z","shell.execute_reply":"2024-04-04T14:23:35.723070Z","shell.execute_reply.started":"2024-04-04T14:22:55.497020Z"},"id":"FG6KCsCNgQgL","outputId":"2c59a3a8-7253-40de-f1d0-cb84e7462037","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data/train_32x32.mat\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 182040794/182040794 [00:23<00:00, 7711289.32it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./data/test_32x32.mat\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 64275384/64275384 [00:11<00:00, 5776874.75it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 200731510.78it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 50473205.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 68295656.86it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<00:00, 12322463.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]}],"source":["# Load and normalize the SVHN dataset\n","transform_svhn = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","trainset_svhn = torchvision.datasets.SVHN(root='./data', split='train', download=True, transform=transform_svhn)\n","trainloader_svhn = DataLoader(trainset_svhn, batch_size=64, shuffle=True, num_workers=2)\n","\n","testset_svhn = torchvision.datasets.SVHN(root='./data', split='test', download=True, transform=transform_svhn)\n","testloader_svhn = DataLoader(testset_svhn, batch_size=64, shuffle=False, num_workers=2)\n","\n","\n","\n","# Load and normalize the MNIST dataset\n","transform_mnist = transforms.Compose([\n","    transforms.Resize((32, 32)),  # Resize to be compatible with SVHN\n","    transforms.Grayscale(num_output_channels=3),  # Convert 1 channel grayscale to 3 channel grayscale\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","testset_mnist = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform_mnist)\n","testloader_mnist = DataLoader(testset_mnist, batch_size=64, shuffle=False, num_workers=2)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T14:23:47.031123Z","iopub.status.busy":"2024-04-04T14:23:47.030208Z","iopub.status.idle":"2024-04-04T14:23:47.043128Z","shell.execute_reply":"2024-04-04T14:23:47.041962Z","shell.execute_reply.started":"2024-04-04T14:23:47.031085Z"},"id":"Rb5CwzwigUDR","trusted":true},"outputs":[],"source":["def train(model, trainloader, criterion, optimizer, device, epochs):\n","    model.train()\n","    loss_values = []  # List to store loss values\n","\n","    for epoch in range(epochs):  # loop over the dataset multiple times\n","        running_loss = 0.0\n","        for i, data in enumerate(trainloader, 0):\n","            inputs, labels = data\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        # Print the average loss of the entire epoch\n","        avg_loss = running_loss / len(trainloader)\n","        print(f'[{epoch + 1}] loss: {avg_loss:.3f}')\n","        loss_values.append(avg_loss)\n","\n","    # Plot the training loss\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(loss_values, label='Training Loss')\n","    plt.title('Training Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","\n","\n","\n","def evaluate(model, testloader, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    accuracy = 100 * correct / total\n","    return accuracy"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aPH9XfzRgW2z","outputId":"78a3e36c-e8e0-47f3-9a6c-16f5d5a7cc81"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1,   200] loss: 1.991\n","\n","[1,   400] loss: 0.685\n","\n","[1,   600] loss: 0.517\n","\n","[1,   800] loss: 0.456\n","\n","[1,  1000] loss: 0.417\n","\n","Accuracy of the network on the SVHN test images: 88.31%\n","\n","[2,   200] loss: 0.290\n","\n","[2,   400] loss: 0.290\n","\n","[2,   600] loss: 0.294\n","\n","[2,   800] loss: 0.280\n","\n","[2,  1000] loss: 0.286\n","\n","Accuracy of the network on the SVHN test images: 90.16%\n","\n","[3,   200] loss: 0.183\n","\n","[3,   400] loss: 0.173\n","\n","[3,   600] loss: 0.190\n","\n","[3,   800] loss: 0.184\n","\n","[3,  1000] loss: 0.189\n","\n","Accuracy of the network on the SVHN test images: 90.88%\n","\n","[4,   200] loss: 0.109\n","\n","[4,   400] loss: 0.112\n","\n","[4,   600] loss: 0.115\n","\n","[4,   800] loss: 0.111\n","\n","[4,  1000] loss: 0.123\n","\n","Accuracy of the network on the SVHN test images: 90.88%\n","\n","[5,   200] loss: 0.063\n","\n","[5,   400] loss: 0.059\n","\n","[5,   600] loss: 0.068\n","\n","[5,   800] loss: 0.073\n","\n","[5,  1000] loss: 0.081\n","\n","Accuracy of the network on the SVHN test images: 91.03%\n","\n","[6,   200] loss: 0.039\n","\n","[6,   400] loss: 0.038\n","\n","[6,   600] loss: 0.036\n","\n","[6,   800] loss: 0.036\n","\n","[6,  1000] loss: 0.047\n","\n","Accuracy of the network on the SVHN test images: 90.93%\n","\n","[7,   200] loss: 0.029\n","\n","[7,   400] loss: 0.026\n","\n","[7,   600] loss: 0.025\n","\n","[7,   800] loss: 0.031\n","\n","[7,  1000] loss: 0.031\n","\n","Accuracy of the network on the SVHN test images: 90.66%\n","\n","[8,   200] loss: 0.018\n","\n","[8,   400] loss: 0.017\n","\n","[8,   600] loss: 0.015\n","\n","[8,   800] loss: 0.016\n","\n","[8,  1000] loss: 0.016\n","\n","Accuracy of the network on the SVHN test images: 91.35%\n","\n","[9,   200] loss: 0.011\n","\n","[9,   400] loss: 0.010\n","\n","[9,   600] loss: 0.008\n","\n","[9,   800] loss: 0.009\n","\n","[9,  1000] loss: 0.010\n","\n","Accuracy of the network on the SVHN test images: 91.75%\n","\n","[10,   200] loss: 0.005\n","\n","[10,   400] loss: 0.005\n","\n","[10,   600] loss: 0.007\n","\n","[10,   800] loss: 0.008\n","\n","[10,  1000] loss: 0.009\n","\n","Accuracy of the network on the SVHN test images: 91.50%\n"]}],"source":["# Setup and repeat Train\n","net = ResNet18()\n","net = net.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n","\n","train(net, trainloader_svhn, criterion, optimizer, device, num_epochs)"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mqFyR9SRgW0d","outputId":"f986b3f9-6c88-45b1-df36-cbd1bff3cb34"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the network on the SVHN test images: 91.50%\n"]}],"source":["# Test\n","svhn_accuracy = evaluate(net, testloader_svhn, device)\n","print(f'Accuracy of the network on the SVHN test images: {svhn_accuracy:.2f}%')\n","\n","mnist_accuracy = evaluate(net, testloader_mnist, device)\n","print(f'Accuracy of the network on the MNIST test images: {mnist_accuracy:.2f}%')"]},{"cell_type":"markdown","metadata":{"id":"IwsGHUjD-Efe"},"source":["## 1.2. Enhance the generalization"]},{"cell_type":"markdown","metadata":{"id":"JeieJTCU-Efe"},"source":["### 1.2.1 Model architecture modification"]},{"cell_type":"markdown","metadata":{"id":"HKG6Dx8x-Eff"},"source":["### 1.2.2. Loss function"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"Cjr_8kQQ-Eff"},"outputs":[],"source":["class LabelSmoothingCrossEntropyLoss(nn.Module):\n","    def __init__(self, smoothing=0.1):\n","        super(LabelSmoothingCrossEntropyLoss, self).__init__()\n","        self.smoothing = smoothing\n","\n","    def forward(self, input, target):\n","        log_probs = F.log_softmax(input, dim=-1)\n","\n","        # Compute the smoothed labels\n","        num_classes = input.size(-1)\n","        with torch.no_grad():\n","            true_dist = torch.zeros_like(log_probs)\n","            true_dist.fill_(self.smoothing / (num_classes - 1))\n","            true_dist.scatter_(1, target.data.unsqueeze(1), 1.0 - self.smoothing)\n","\n","        # Return the average loss\n","        return torch.mean(torch.sum(-true_dist * log_probs, dim=-1))"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"I9yw64CD-Eff"},"outputs":[],"source":["# Setup and repeat Train\n","net = ResNet18()\n","net = net.to(device)\n","criterion = LabelSmoothingCrossEntropyLoss(smoothing=0.25)\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n","\n","train(net, trainloader_svhn, criterion, optimizer, device, num_epochs)"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uqT9Zfv4keRm","outputId":"7a22e815-c9dc-4ed0-b303-a16c00286a31"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the network on the SVHN test images: 92.11%\n","\n","Accuracy of the network on the MNIST test images: 64.97%\n"]}],"source":["# Test\n","svhn_accuracy = evaluate(net, testloader_svhn, device)\n","print(f'Accuracy of the network on the SVHN test images: {svhn_accuracy:.2f}%')\n","\n","mnist_accuracy = evaluate(net, testloader_mnist, device)\n","print(f'Accuracy of the network on the MNIST test images: {mnist_accuracy:.2f}%')"]},{"cell_type":"markdown","metadata":{"id":"HBPIZKiE-Efg"},"source":["### 1.2.3 Data agumentaiton"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-04-04T14:36:24.353469Z","iopub.status.busy":"2024-04-04T14:36:24.352665Z","iopub.status.idle":"2024-04-04T14:36:26.656313Z","shell.execute_reply":"2024-04-04T14:36:26.655528Z","shell.execute_reply.started":"2024-04-04T14:36:24.353435Z"},"id":"z6y21RljpKiq","outputId":"e234f45d-e8a9-4160-d038-c2c2d2299970","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using downloaded and verified file: ./data/train_32x32.mat\n"]}],"source":["from torchvision import transforms\n","\n","batch_size = 64\n","\n","# Define the augmentation pipeline\n","augmentation_transforms = transforms.Compose([\n","    transforms.RandomRotation(degrees=10),  # Rotate +/- 10 degrees\n","    # 92.7 , 70.2\n","    # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 10% translation\n","    # 94.9 , 67.2\n","    transforms.RandomResizedCrop(size=(32, 32), scale=(0.8, 1.2)),  # Scaling between 80% and 120%\n","    # 95.1 , 67.9\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Randomly change brightness, contrast, and saturation\n","    # 95.8 , 74.9\n","    # transforms.RandomPerspective(distortion_scale=0.5),  # perspective transformations\n","    # 95.9 , 67.0\n","    \n","    # Top gener: Color + Rotate + Size\n","    # 95.8 , 81.1\n","    # Top acc: Perspective + Color + Size\n","    # 96.2 , 76.4\n","    # Intersection: Color + Size\n","    # 96.4 , 72.1\n","    # All\n","    # 95.7 , 66.0\n","    \n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# Apply the augmentation pipeline only to the training data\n","trainloader_svhn = torch.utils.data.DataLoader(\n","    datasets.SVHN(root='./data', split='train', download=True, transform=augmentation_transforms),\n","    batch_size=batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-04-04T14:42:24.770818Z","iopub.status.busy":"2024-04-04T14:42:24.770427Z"},"id":"4BQ31B3NpKLd","outputId":"833dbe0d-d26b-4e04-c428-9616768d2065","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[1,   500] loss: 0.354\n","[1,  1000] loss: 0.329\n","[2,   500] loss: 0.301\n","[2,  1000] loss: 0.291\n","[3,   500] loss: 0.275\n","[3,  1000] loss: 0.274\n","[4,   500] loss: 0.251\n","[4,  1000] loss: 0.261\n","[5,   500] loss: 0.237\n","[5,  1000] loss: 0.237\n","[6,   500] loss: 0.230\n","[6,  1000] loss: 0.227\n"]}],"source":["# Setup and repeat Train\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n","\n","train(net, trainloader_svhn, criterion, optimizer, device, num_epochs)"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"execution":{"iopub.execute_input":"2024-04-04T14:03:48.726774Z","iopub.status.busy":"2024-04-04T14:03:48.726449Z","iopub.status.idle":"2024-04-04T14:03:56.319845Z","shell.execute_reply":"2024-04-04T14:03:56.318655Z","shell.execute_reply.started":"2024-04-04T14:03:48.726743Z"},"id":"U3nA1ea2puJS","outputId":"56d014ce-1a12-4f27-e3c9-b04fe6c15c29","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the network on the SVHN test images: 95.70%\n","Accuracy of the network on the MNIST test images: 66.05%\n"]}],"source":["# Test\n","svhn_accuracy = evaluate(net, testloader_svhn, device)\n","print(f'Accuracy of the network on the SVHN test images: {svhn_accuracy:.2f}%')\n","\n","mnist_accuracy = evaluate(net, testloader_mnist, device)\n","print(f'Accuracy of the network on the MNIST test images: {mnist_accuracy:.2f}%')"]},{"cell_type":"markdown","metadata":{},"source":["### 1.2.4 Transfer learning"]},{"cell_type":"markdown","metadata":{},"source":["Need to run earlier dataloaders to remove the effect of recent data agumentation"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T14:29:05.011906Z","iopub.status.busy":"2024-04-04T14:29:05.010937Z","iopub.status.idle":"2024-04-04T14:29:05.289196Z","shell.execute_reply":"2024-04-04T14:29:05.288402Z","shell.execute_reply.started":"2024-04-04T14:29:05.011871Z"},"id":"5plBgThrpJx5","trusted":true},"outputs":[],"source":["# Setup and repeat Train\n","net = models.resnet18(pretrained=True)\n","net = net.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n","\n","train(net, trainloader_svhn, criterion, optimizer, device, num_epochs)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-04T14:24:00.447515Z","iopub.status.idle":"2024-04-04T14:24:00.447851Z","shell.execute_reply":"2024-04-04T14:24:00.447699Z","shell.execute_reply.started":"2024-04-04T14:24:00.447686Z"},"trusted":true},"outputs":[],"source":["# Test\n","svhn_accuracy = evaluate(net, testloader_svhn, device)\n","print(f'Accuracy of the network on the SVHN test images: {svhn_accuracy:.2f}%')\n","\n","mnist_accuracy = evaluate(net, testloader_mnist, device)\n","print(f'Accuracy of the network on the MNIST test images: {mnist_accuracy:.2f}%')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
